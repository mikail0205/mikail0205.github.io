---
title: [CS231n] Lec01 Computer vision[컴퓨터 비전]
description: Computer vision에 대한 역사와 개념 설명 cs231n강의 참고
categories:
 - Computer Vision
 - Machine Learning
tags: ComputerVision, ML
---
## Computer Vision
컴퓨터 비전은 visual data[시각 데이터]에 대한 연구이다. Visual data의 양은 계속해서 증가하고 있는데, 2017년에 모든 인터넷의 80%에 해당하는 자료가 비디오가 될 것이다는 CISCO의 연구도 있었다.
![](https://www.bleepstatic.com/content/hl-images/2017/03/20/Cisco.jpg)

Visual data는 문제가 하나 있는데, 바로 이해하기가 너무 어렵다는 것이다. Visual data를 가끔 인터넷의 암흑 물질(Dark matter)이라고 비유해서 부르기도 하는데. 암흑 물질은 우주의 질량의 놀랍도록 많은 부분을 차지하고 있지만 다양한 천체에 대한 중력의 존재로 암흑 물질이 존재하는 것을 알뿐 직접적으로 관찰할 수는 없다.
> 암흑물질 (Dark Matter) : 우주의 총 에너지의 대략 23%를 차지하며, 나머지는 가시광선으로 관측할 수 있는 물질과 암흑 에너지(Dark energy)로 이루어진다는 것이 현재의 이론. 물질만을 고려하면 암흑 물질은 우주 전체 물질의 84.5%를 차지하며, 암흑에너지와 암흑물질은 전체 구성 중 약 96%를 차지한다.

그리고 인터넷상의 visual data 역시 마찬가지인데, 인터넷을 둘러싼 대부분의 bits로 구성되어 있지만 알고리즘이 실제로 들어가서 웹상의 모든 visual data를 정확히 무엇이 구성하는지를 이해하고 보는 것은 매우 어렵다.

## History of Vision
### Biological vision
Vision에 대한 역사는 많은 시간을 거슬러 가야 하는데 (정확히는 5억 4300만 년 전) 그 당시 지구는 대부분 물로 덮여 있었고 아주 적은 생명만이 바다를 떠다녔을 뿐이었다. 그러다 정말 놀라운 일이 5억 4000만 년 전에 발생하게 되는데. 화석 연구 동물연구 학자가 매우 짧은 기간 동안(1000만 년) 동물의 종류가 폭발적으로 증가했다는 것을 찾아냈다.

몇 가지에서 수십만 개로 넘어가게 되는데 이것은 분명 이상한 일일 것이다. 과연 무엇이 이 현상을 만들었을까? 많은 이론이 있기는 하지만 오랜 기간 동안 미스터리로 남았다. 진화 생물학자들은 이것을 진화의 빅뱅이라고 부르는데, 몇 년 전 호주 동물학자인 Andrew Parker가 화석 연구에서 가장 설득력 있는 이론을 제시하게 된다. 약 5억 4000만 년 전에 첫 번째 동물이 눈을 개발하고 시력이 발달함에 따라 이 폭발적인 진화 단계가 시작되었음을 발견한 것이다.

일단 볼 수 있게 되면 삶은 훨씬 더 능동적이게 된다. 일부 포식자는 사냥을 하고 피식자는 포식자로부터 도망쳐야 하므로 시력의 진화 또는 발명은 진화론 적 군비 경쟁을 시작하게 하였으며 종족으로 살아남기 위해서는 동물이 빠르게 진화해야만 했다. 그리고 이것이 동물의 vision의 시작이다.

5억 4000만 년이 지난 후에 시각은 거의 모든 동물, 특히 영리한 동물의 가장 큰 감각 기관으로 발전했는데.
>인간은 시각 처리에 관련된 피질(cortex)의 거의 50%에 해당하는 뉴런을 가지고 있다.

우리가 생존하고, 일하고, 움직이고, 조작하고, 의사소통하고 그 외 많은 것들을 가능하게 하는 가장 큰 감각 시스템으로 시각은 동물 특히 영리한 동물에게는 정말로 중요하다.

### Human vision
기계적인 시각 혹은 카메라를 만드는 인간의 역사는 어떨까? 초기 카메라 중 하나는 1600년대 르네상스 시대의 카메라 'Obscura'에서 나온 것이다.
![](http://www.creativephotography.org/exhibits/richard-torchia/trchedu/diagrams/coenxx.gif "Obscura")
이 카메라는 핀홀(Pinhole) 카메라 이론에 기반을 둔 카메라이며 동물들이 빛을 모으기 위해 개발한 초기의 눈과 매우 유사하다.
생물 학자들은 시력의 메커니즘을 연구하기 시작했는데, 영감을 얻은 computer vision뿐만 아니라 동물의 시각과 인간 시각의 가장 영향력 있는 작업 중 하나는 전기생리학(electrophysiology)을 사용하는 1950~60년대 Hubel과 Wiesel이 수행한 작업이다. 그들이 물었던 질문은
> 영장류와 포유류에서와 같은 시각적 메커니즘은 무엇인가?였다.

그래서 그들은 시각적 처리 관점에서 인간의 뇌와 어느 정도 유사한 고양이 두뇌를 연구하기로 결심했으며, 그들이 한 일은 주요 시각 피질 영역이 있는 고양이 두뇌의 뒷부분에 전극을 찔러 넣은 다음 고양이 뇌의 주요 시각 피질의 뒷부분의 뉴런을 흥분시키는 자극을 보는 것이었다.
![](https://user-images.githubusercontent.com/32008883/30751966-dea3b4c2-9ff5-11e7-870d-44140ff3b480.JPG)

그렇게 알게 된 사실은 고양이 두뇌의 주요 시각 피질 부분에 많은 종류의 세포가 있다는 것이었다. 그러나 가장 중요한 세포 중 하나는 특정 방향으로 움직일 때 지향성 가장자리에 반응하는 단순 세포였다. 물론 더 복잡한 세포도 있지만, 그들이 발견한 것은 시각적인 처리가 시각적 세계의 단순한 구조, 지향적인 윤곽기반에서부터 시작되고 정보가 시각적 처리 경로를 따라 이동함에 따라 뇌가 복잡한 시각 세계를 인식할 때까지 시각 정보의 복잡성을 구축하게 된다.

### Computer vision

따라서 컴퓨터 비전의 역사 역시 1960 년대 초반부터 시작된다. 'Block world'는 Larry Roberts가 출판 한 작품으로, 시각적 세계가 단순한 기하학적 모양으로 단순화되고 목표가 인식 할 수 있는 컴퓨터 비전의 첫 번째 PHD 학위 논문 중 하나로 널리 알려져 있다.
![](http://www.packet.cc/images/mach-per-fig2.jpg "Block world")
1966 년에 "Summer Vision Project"라는 유명한 MIT 여름 프로젝트가 있었는데. 이 프로젝트의 목표는 visual system의 중요한 부분을 구성하는 데 여름 노동자들을 효과적으로 사용하려는 시도였다. 50여 년이 지난 지금도 컴퓨터 비전 분야는 한 여름 프로젝트에서 전 세계 수 천명의 연구자들로 피어나고 있으며, 여전히 vision의 가장 근본적인 문제 중 일부를 다루고 있다. 우리는 아직 vision을 해결하지 못했지만 인공 지능 분야에서 가장 중요하고 빠르게 성장하는 분야 중 하나로 성장했다.

또 한 명의 경의를 표해야 할 사람은 'David Marr'이다. MIT 과학자로 1970년대 후반에 그의 vision에 대한 생각과 우리가 computer vision에 대해 어떻게 접근해야 하는지 그리고 컴퓨터로 시각적 세계(visual world)를 인식할 수 있게 하는 알고리즘을 개발하는 데에 대한 영향력 있는 책을 저술했다.

그 책에서는 이미지를 취하고 시각적 세계의 마지막인 3차원 표현에 도달하기 위해 여러 과정을 거쳐야 한다는 것이다.

![](http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/GOMES1/img1.gif)

첫 번째 과정은 '원시 스케치 (primal sketch)'라고 부른다. 대부분 가장자리, 바, 끝, 가상 선, 커브, 경계가 표현되는 곳이며 신경과학자(neuroscientist)들이 보았던 것에서 영감을 받았다. Hubel과 Wiesel은 시각적 처리의 초기 단계가 모서리(edge)와 같은 간단한 구조와 관련이 있다고 말했다.
다음 단계는 "2-and-half-D sketch"라고 부른다. visual scene의 surfaces, depth information, layers 또는 시각 화면의 불연속 부분을 함께 조각하기 시작한 다음 결국 모든 것을 모아서 surface 및 volumetric primitives 등을 통해 계층적으로(hierarchically organized) 구성된 3차원 모델을 갖게 된다. 따라서 이것은 vision이 무엇인지와 그러한 사고방식에 대한 매우 이상적인 사고 과정이었다.
실제로 수십 년 동안 computer vision을 지배해 왔으며 학생들이 시각 영역(field of visual)에 들어가서 시각적 정보를 분석하는 방법을 생각하는 데 매우 직관적인 방법이기도 하다.

1970년대에 또 하나의 매우 중요한 세미나 그룹이 생겨났다. 사람들이 "단순한 블록 세계를 넘어서 어떻게 현실 세계의 대상을 인식하고 표현할 수 있을까?"하는 질문을 하기 시작했다. 그 당시를 생각해보면, 사용 가능한 데이터가 거의 없다시피 했으며 컴퓨터는 느리고 PC도 주변에 있지 않았지만 컴퓨터 과학자들은 우리가 어떻게 물체를 인식하고 표현할 수 있는지 생각하기 시작했다. 그래서 Palo Alto의 스탠포드와 SRI(Standford Research Insititue)의 두 그룹에서 과학자들이 유사한 아이디어를 제안했는데 하나는 일반화된 실린더(generalized cylinder)라고 부르고 다른 하나는 그림구조(pictorial structure)라고 불렀다.

![](https://user-images.githubusercontent.com/32008883/30751987-f03d50e4-9ff5-11e7-8650-70da272845b6.JPG)

기본 개념은 모든 객체가 단순한 기하학적 기본 요소로 구성된다는 것이다. 예를 들어 사람은 "일반화된 실린더" 모양으로 함께 결합될 수 있거나 혹은 사람은 그들의 탄성 거리(elastic distance)에 있는 핵심 부분(critical part)에 의해 결합될 수 있다는 것. 따라서 어느 표현이라도 객체의 복잡한 구조를 더 단순한 형태의 집합과 기하학적 구성으로 축소하는 방법이다.

이런 작업들은 몇년간 꽤나 영향력이 있었으며 1980년대에는 David Lowe가 단순한 세계 구조에서 시각적 세계를 재구성하거나 인식하는 방법을 생각했다.

그 당시 computer vision의 과제가 무엇인지 생각하려는 많은 노력들이 있었는데. 1960 ~ 80년대에는 물체 인식에 대한 문제를 풀기가 너무 어려웠다. 위의 내용들은 분명 야심차고 대담한 시도이지만 장난 수준에 불과하다. 현실세계에서 작동할 수 있는 무언가를 제공한다는 측면에서는 많은 진전이 없었기 때문. 그래서 사람들은 vision을 해결하는 데 있어 무엇이 문제인지 생각하게 된는데 한 가지 중요한 질문은 다음과 같다.
> 객체 인식이 너무 어려울 경우, 객체 분할을 먼저 수행해야 한다. 즉, 이미지를 가져와서 픽셀을 의미 있는 영역으로 그룹화해야 하는 것.

우리가 그룹으로 묶인 픽셀을 사람이라고 부르는지 알 수 없지만 그 배경을 보고 사람에게 속한 모든 픽셀들을 추출할 수는 있는데. 이것을 영상분할(image segmentation)이라고 한다.

영상분할 문제에 대한 그래피 이론 알고리즘을 사용한 아주 초기의 작품이 있는데. Computer vision의 얼굴 인식에 대한 문제이다. 1999년에서 2000년 사이에 machine learning이 추진력을 얻기 시작하는데. 이 기술은 verctor machine, boosting과 신경망의 첫 번째 물결을 포함한 그래픽 모델이다. 많은 기여를 한 작업은 AdaBoost 알고리즘을 사용하여 Paul Viola와 Micheal Jones가 실시간으로 얼굴을 탐지하는 작업이었다. 2001년에는 컴퓨터 칩이 느렸지만 거의 실시간으로 이미지에서 얼굴을 감지 할 수 있었고 2006년 5월 신문에 발표한 후 Fujifilm은 실시간 얼굴 탐지가 가능한 최초의 디지털 카메라를 출시하게된다.






## Release note
2018-05-20 : First upload
2018-05-22 : Add


## References
[CS231n]<https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk>